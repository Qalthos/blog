<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Why Not Wingnut?</title><link href="http://qalthos.github.io/blog/" rel="alternate"></link><link href="http://qalthos.github.io/blog/feeds/tag/data-alchemy.atom.xml" rel="self"></link><id>http://qalthos.github.io/blog/</id><updated>2012-08-22T22:16:00-04:00</updated><entry><title>Recent Projects: Democrat &amp; Chronicle</title><link href="http://qalthos.github.io/blog/recent-projects-democrat-chronicle.html" rel="alternate"></link><updated>2012-08-22T22:16:00-04:00</updated><author><name>Nathaniel Case</name></author><id>tag:qalthos.github.io/blog,2012-08-22:recent-projects-democrat-chronicle.html</id><summary type="html">&lt;p&gt;One of the new projects I had this summer was a project proposed by the
&lt;a class="reference external" href="http://www.democratandchronicle.com/"&gt;Democrat &amp;amp; Chronicle&lt;/a&gt;. The project involved access to a selection of
emails sent to the Greece school district in the wake of the YouTube
video involving several of their students. The idea was that we would
get a dump of email bodies and try to glean some information out of
them.&lt;/p&gt;
&lt;p&gt;The first hurdle, unfortunately, was getting at the information. Shortly
after we were approached with the request, I received an Access file
containing around 5000 email bodies to go through. Being what we are,
most of the resources in the FOSSBox are oriented around Linux, and no
one about had a copy of Access installed to get the data into a more
friendly format.&lt;/p&gt;
&lt;p&gt;In theory, there are ODBC drivers for access databases, just like there
are for any other database system. In practice, however, they seem to
only exist for Windows machines which, while not surprising, was
disappointing. This led me to dig out an old VirtualBox VM with Windows
XP on it, install the Access drivers from Microsoft, and throw
LibreOffice on it, too. There's other ways I could have gotten this done
instead of LibreOffice, but I was still hoping this could be a simple
action at the moment.&lt;/p&gt;
&lt;p&gt;LibreOffice Base eventually got into the Access file, but then the
troubles started again. It initially prompted me to save a LibreOffice
database file, which sounded great to me... it could export it
immediately, then I could copy it over and finish the task in Linux.
Unfortunately, all this file did was create a small wrapper around the
Access file, telling LibreOffice where the file was located, and what
was needed to open it. So now I was back to trying to export the data.
LibreOffice, though, was not willing to play along. I admit I am less
than familiar with the Base component of LibreOffice, however some
exploration and more searching online led me to believe I could not do
the simple translation of data from one format to another from within
Base.&lt;/p&gt;
&lt;p&gt;Instead, I needed to select the table I was interested in (the only
table in the database), tell LibreOffice to copy the table, then open a
new spreadsheet in LibreOffice Calc and save the data that way. While
this makes some sense to me (Base being simply for basic interaction
with databases, Calc for manipulating raw data), I was dismayed that I
could not find some way to export a single table to a common data
format, like CSV, instead of having to go through yet another step. In
any case, once I dumped the data into Calc, I could easily save it to
CSV, drop that into my real computer, stop the VM, and get to work for
real.&lt;/p&gt;
&lt;p&gt;The end result is &lt;a class="reference external" href="https://github.com/Qalthos/mail_scrape"&gt;this&lt;/a&gt;. I'm not sure it will ever be of any
particular use to anyone other than myself to remind me how to use the
Python NLTK module (whose documentation seems to be geared more towards
researchers than those already familiar with Python), and is hardcoded
to certain facets of the data I was given, but it does manage to do a
few things, and at each step it dumps the state of the data to a file so
I can inspect the process and consider possible improvements.&lt;/p&gt;
&lt;/p&gt;</summary><category term="journalism"></category><category term="data alchemy"></category></entry><entry><title>Introducing: FOSS@RIT Timeline Year in Review</title><link href="http://qalthos.github.io/blog/introducing-fossrit-timeline-year-in-review.html" rel="alternate"></link><updated>2012-08-22T22:15:00-04:00</updated><author><name>Nathaniel Case</name></author><id>tag:qalthos.github.io/blog,2012-08-22:introducing-fossrit-timeline-year-in-review.html</id><summary type="html">&lt;p&gt;Yesterday, I sat down with Remy and went over the last of the things we
need to do to close out the summer. There was a long list of items,
split into two sections, each containing the same sort of stuff.
FOSS&amp;#64;RIT has done a lot of stuff in the past year, and we need to be
able to tell people about it.&lt;/p&gt;
&lt;p&gt;The first section concerned the few things we had done that hadn't yet
hit &lt;a class="reference external" href="http://foss.rit.edu/timeline/"&gt;Timeline&lt;/a&gt;. This was a fairly sizable chunk of things, and we
needed a good, rapid-entry way of getting more events in there. No
problem, I had done some work on that before, I could get it running and
dump events in there no problem.&lt;/p&gt;
&lt;p&gt;The second (and slightly longer) list dealt with things we needed to
compile some information about as a sort of &amp;quot;here's what we've done&amp;quot;
report. The list of things that needed to be in that was... just about
the same as the last one. Remy planned to go through the Timeline site
and add entries from it, categorize them, and push it to foss.rit.edu.&lt;/p&gt;
&lt;p&gt;This deeply concerned me on two distinct levels. First was the part of
me that never liked writing. I've mentioned it here once before, and I
feel I've gotten better since then, but the concept of wading through
all that data to write a report was not something that made me happy.
The other part was that all the things in the second list had to be
added to the timeline at some point anyway, or were likewise available
from other sources. When Remy showed me what he had written for 2010, it
was obvious this could be easily replicated in code.&lt;/p&gt;
&lt;p&gt;About an hour of JavaScript wrangling later, I had made &lt;a class="reference external" href="http://foss.rit.edu/timeline/2011.html"&gt;this&lt;/a&gt;. Also
&lt;a class="reference external" href="http://foss.rit.edu/timeline/2010.html"&gt;this&lt;/a&gt;, and if you're reading this from about a year in the future,
&lt;a class="reference external" href="http://foss.rit.edu/timeline/2012.html"&gt;this&lt;/a&gt; should even exist. It's still needs some tweaking, the years are
hardcoded in the documents, the pages aren't linked from the main
timeline page, and I'd rather have them all use one common file than
make a new one each year, but it works, it's fairly similar to what was
handwritten last year, and it gets updated every time something gets
added to Timeline.&lt;/p&gt;
&lt;/p&gt;</summary><category term="data alchemy"></category><category term="jQuery"></category><category term="timeline"></category></entry></feed>