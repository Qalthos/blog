<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Why Not Wingnut?</title><link href="http://nathanielca.se/" rel="alternate"></link><link href="http://nathanielca.se/feeds/tag/widgets.atom.xml" rel="self"></link><id>http://nathanielca.se/</id><updated>2011-06-21T22:56:00-04:00</updated><entry><title>Back up to Speed</title><link href="http://nathanielca.se/civx/back-up-to-speed.html" rel="alternate"></link><updated>2011-06-21T22:56:00-04:00</updated><author><name>Nathaniel Case</name></author><id>tag:nathanielca.se,2011-06-21:civx/back-up-to-speed.html</id><summary type="html">&lt;p&gt;I've almost closed &lt;a class="reference external" href="https://fedorahosted.org/civx/ticket/106"&gt;bug #106&lt;/a&gt;. I've done all I can do for now, until I
can figure out how to attribute actions to senators. Until then, I
should comment out the 'actions' tab tomorrow with a note letting
whoever tries this next what I've already tried.
There is still some work to do in this code, particularly with fixing
the hacky Assembly scraping I wrote last year which also broke. However,
considering that the Assembly is not currently one of the bits we are
trying to expose (and they don't have a nice public API like the
Senate), it probably won't get done for a little while.
When I left yesterday, I had exposed the senator's social page, but none
of the other tabs were showing up. The problem for this turned out to be
that the image representing the tab was corrupted and the text beneath
it was white, making it overall look like the tab was invisible. Once I
got a new image for the tab, they all suddenly appeared, though only the
bills had any information.
The next thing to fix was the scraping of the committees, whose pages
had also changed subtly in the past few months. Fixing this was much
less annoying than building them the first time, and I was able to
remove a lot of old shims in the code from when I was first being
introduced to &lt;a class="reference external" href="http://www.crummy.com/software/BeautifulSoup/"&gt;BeautifulSoup&lt;/a&gt;. Some of my later changes made this
particularly easy, and since BeautifulSoup is so powerful, I was able to
restore access to the data with relative ease. As a bonus, as soon as I
had committees back up, the tabs for votes and meetings came with it for
free. Suddenly, I was almost there!
The final problem I encountered today is actually not a new one, but one
we struggled with last year, and one I now feel confident I have
actually fixed and understand now. Once I got all the data pulling
again, a few of the pages would crash the server with
UnicodeDecodeErrors.
As a warning, some heavy Python is about to come down
UnicodeDecodeError is an error which happens (generally) when attempting
to decode a string into a Unicode object. This is generally a great
thing to do, as Python strings are generally encoded in the relatively
restrictive ASCII, which does not have characters for any of the more
exciting characters like accents and non-latin symbols. Unicode has no
such restrictions, and indeed has data for many, many more symbols, at
the cost of a few more bits of storage per character.
So why were we getting this error? The relevant line of code was 's =
unicode(s)' and was contained within &lt;a class="reference external" href="http://pythonpaste.org/webob/#introduction"&gt;WebOb&lt;/a&gt; code, not something I was
going to be able to modify successfully. Still, even this shouldn't be a
problem. The purpose of this function is to turn strings to Unicode
strings.
Except I didn't have a string, I already had a Unicode string.
Even this shouldn't be a problem, except that unicode() tries to
interpret its input as a string and then turn it into a Unicode string.
And while Unicode strings can be easily represented as normal strings,
the default of the unicode() function is to try to interpret those
strings as ASCII strings, and I had accents in the strings. These
strings were representing the names of the senators, so I had to make
sure it came out right.
In order to solve this, I had to reversibly represent these names as a
sequence of ASCII characters.
There are a few ways to replace out-of-bound characters when changing
strings into lesser encodings, and I had two useful ones to chose from.
The obvious one to chose was to change the characters into XML character
entities, however this quickly turned out to be insufficient. While
&amp;amp;#233; correctly showed up as Ã© on the page, this string is used to
represent the name everywhere, including in the internal URL
representing the page. And the ampersand was quickly stripped out as a
broken argument to the URL, leading to a page for a nonexistent Senator.
Looking through the code, there were three distinct uses for the name
string. The first, which had started all this, was as an ASCII key to a
dictionary which needed to be authoritative but not necessarily
accurate. In other words, I needed it to be the same everywhere, but it
didn't necessarily need to be the correct name of the senator. The
second was the use on the generated web page, which needed to be as
accurate as possible to the Senator's actual name, as it is going to be
viewed publicly. The third, and the current stickler was the name in the
URL. Again, this had to be authoritative but not necessarily accurate.
This one, however, had to also only include web-safe characters, of
which &amp;amp;, # and ; do not qualify.
I mulled this over for a while, thinking up more and more elaborate
schemes for intercepting the names before they reached critical areas,
but none of it was terribly good coding practice. After far too much
thinking, I realized the obvious answer: have separate internal and
external names. The system still relies on the senator's name, which is
still a questionable practice given the multiple spellings of names that
occasionally pop up, (but mostly because I remember &lt;a class="reference external" href="http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/"&gt;this post&lt;/a&gt;, which
is something you should always keep in mind when programming around
names. The display name, on the other hand, has none of the restrictions
on characters (though it still needs to be ASCII to display properly),
but by using XML entities, we can make any character we want without
problems.
This was a long path to take to get back to where we were, but I think
that I really understand Python's Unicode in a way I never grasped
before. This should definitely help in the future as Unicode is a very
important part of coding portable applications and that's something I
want to do.&lt;/p&gt;
</summary><category term="peopledashboard"></category><category term="widgets"></category><category term="scrapers"></category><category term="SURS"></category></entry><entry><title>Shelves and Shoves</title><link href="http://nathanielca.se/civx/shelves-and-shoves.html" rel="alternate"></link><updated>2011-06-21T22:56:00-04:00</updated><author><name>Nathaniel Case</name></author><id>tag:nathanielca.se,2011-06-21:civx/shelves-and-shoves.html</id><summary type="html">&lt;p&gt;Today is the day to hit &lt;a class="reference external" href="https://fedorahosted.org/civx/ticket/105"&gt;bug #105&lt;/a&gt;, another of the leftover bugs from
last year.
The story goes something like this: there's a lot of data on
nysenate.gov that is nice to have, but asking for that info on every
call is a little cumbersome. We want to cache as much of the data as we
can, particularly the stuff that's not going to change in the next week
or longer. Previously, I had implemented a simple pylons cache which was
fast, but had no persistent storage, so every time the server went down
it pulled all the info again. And due to the way the scrape was written,
it pulled all the info for all the senators at once, creating quite a
bit of lag before the first page showed up. This clearly wasn't going to
be something we could continue to develop with.
Now, I know nothing about caching data, so I did some poking around in
CIVX to see how it is done elsewhere. Most of the other caches I found
in CIVX code were related to caching text feeds, which were not as
explanatory as I was hoping. Once I felt I had a handle on how things
were done there, I began to try to implement some of it, only to be
shown &lt;a class="reference external" href="http://threebean.wordpress.com/2011/06/08/cached-function-calls-with-expiration-in-python-with-shelve-and-decorator/"&gt;this post&lt;/a&gt; on &lt;a class="reference external" href="http://docs.python.org/library/shelve.html"&gt;shelve&lt;/a&gt;, a Python library for storing arbitrary
data. Combined with the decorator, this seemed to do exactly what I
wanted, namely provide a permanent storage area for a bunch of data with
a configurable expire time. I dumped the code into the dashboard, hooked
the proper inputs up and let it run. The results were... promising, but
not astonishing. The file storage worked, once the data was cached, we
stopped looking to nysenate.gov for data and instead used our own data,
even after server restarts.
The problem was that the file storage seemed to be slower than the
previous memory cache. This is all perfectly reasonable, since disk
access is much slower than memory, and a lot of data has to get pulled
for each senator. The first obvious thing I could do is to re-enable the
memory cache, but this did not seem to help as much as I wanted it to.
At this point, &lt;a class="reference external" href="lewk.org"&gt;Luke&lt;/a&gt; popped up in chat to sat that Moksha had a
&lt;a class="reference external" href="http://pypi.python.org/pypi/shove"&gt;Shove&lt;/a&gt; cache it uses for feeds. Sure enough, back in the files I had
been poking through earlier, there were some references to Shove. Back to
the net, I started to explore what Shove was and how it could help me.
It turns out Shove is mostly drop in compatible with shelve, and aims to
be a more extensible replacement for it. Once I got a handle on how
Shove works differently from shelve (answer, not very), I made a few
tiny tweaks and got a version successfully working with Shove and a
sqlite backend. This didn't make the end result any faster (well maybe a
little, but not much), but there is a lot of room for improvement,
particularly if I can hook into Moksha's own stores. Further, Shove has
its own abilities to cache items in memory in addition to storing them,
which I would like to look into. The best route for efficiencies, I
think is to change how the data gets stored in the cache. Currently all
the data gets pulled at once, which was done to pacify the pylons cache.
However, if I can get individual caches for each senator, then I can
pull smaller volumes of data at a time, hopefully speeding up the
process.
We'll see where I get tomorrow, but so far I'm feeling pretty good about
all this.&lt;/p&gt;
</summary><category term="peopledashboard"></category><category term="widgets"></category><category term="scrapers"></category><category term="SURS"></category></entry><entry><title>Summer of CIVX</title><link href="http://nathanielca.se/civx/summer-of-civx.html" rel="alternate"></link><updated>2011-06-21T22:56:00-04:00</updated><author><name>Nathaniel Case</name></author><id>tag:nathanielca.se,2011-06-21:civx/summer-of-civx.html</id><summary type="html">&lt;p&gt;So I'm back at RIT for the summer working on CIVX again. There's been a
lot of development on Moksha, the software stack CIVX runs on, and not
all of it was a trivial update. Still, many of the problems I
encountered were definitely my fault, not the least of which was
forgetting Arch Linux has switched to Python 3.
Once I was up, I looked into fixing the people dashboard we worked on
last summer. In the meantime, the NYS Senate updated their API for
getting open government data, so I had to figure out the new scheme and
try to make it work. Complicating this is that they still don't have
easy access to grabbing all the current senators, and the page we look
at to get this information changed enough to stop the script from
completing.
I'm actually surprised how quickly I was able to work this out, though
of course this is not even remotely new to me. But despite nearly a year
of inactivity on the project I seem to have gotten back into the swing
of it pretty well.&lt;/p&gt;
</summary><category term="peopledashboard"></category><category term="widgets"></category><category term="SURS"></category></entry><entry><title>The Last Week</title><link href="http://nathanielca.se/civx/the-last-week.html" rel="alternate"></link><updated>2011-06-21T22:56:00-04:00</updated><author><name>Nathaniel Case</name></author><id>tag:nathanielca.se,2011-06-21:civx/the-last-week.html</id><summary type="html">&lt;p&gt;This week has been a mess for a lot of reasons. Let's see what I managed
to get through so far.
One of the things I got to look at this week is threebean's mokshactl
branch of CIVX and Moksha. This is a project to simplify the
administration of a Moksha installation. The project grew out of an
attempt to easily package Moksha and grew into a much larger system
capable of managing most aspects of CIVX at once, and in a very pretty
package, too. It has a few problems, but for the most part, it performs
quite well, and best of all, it will even integrate itself with Moksha,
controlling the necessary aspects of Moksha as well.
In less exciting news, I poked around in the people dashboard while I
had some time and got Assembly members working again. It didn't take
much as I had expected, but served to keep me on task while Remy was in
one of the never ending series of meetings he's had this week.
On a lighter side of things, I put some &lt;a class="reference external" href="http://lobstertech.com/fabulous.html"&gt;fabulous&lt;/a&gt; in the CIVX shell
today as I was working in it. The mokshactl branch is already
fabuloused, and once you see that, there's no coming back. fabulous
makes things very pretty with only a little work.
Other than that not a lot has gone down. Some work has gone into the
polyscraper, but that's nothing worth mentioning at this point. Between
that and some internal matters and hours of meetings and my car
developing a leak in it's brake line, that's all that went down this
week. Tomorrow I get to drive home and hopefully fix my car properly.&lt;/p&gt;
</summary><category term="peopledashboard"></category><category term="widgets"></category><category term="scrapers"></category><category term="SURS"></category><category term="fabulous"></category></entry><entry><title>Boston</title><link href="http://nathanielca.se/civx/boston.html" rel="alternate"></link><updated>2011-01-23T07:14:00-05:00</updated><author><name>Nathaniel Case</name></author><id>tag:nathanielca.se,2011-01-23:civx/boston.html</id><summary type="html">&lt;p&gt;So here we are in OLPC HQ, right in the middle of MIT. It's pretty sweet
having &lt;a class="reference external" href="http://lewk.org/"&gt;Luke&lt;/a&gt; around again to hack CIVX with us.
I've had a lot to do in the past few days. Remy's been showing me
scrapers and models, and I've been helping transition &lt;a class="reference external" href="http://foss.rit.edu/user/17"&gt;Kate's&lt;/a&gt; people
dashboard into an integrated component or integrating &lt;a class="reference external" href="http://rebeccanatalie.com/"&gt;Rebecca's&lt;/a&gt; theme
changes on the side. It's been hectic and fun and tough, but I finally
feel like I'm contributing to a project, something with substance and
goals, not just writing code to accomplish a task like some of my
previous co-ops. Being in a team this large helps, especially when we
pull in outside help like Luke, but I think it's mainly Remy's
infectious excitement for the project. When he gets down to work, one
can't help but feel his vision and be excited for the possibilities.
Unfortunately, that means I had precious little time to pay attention to
the other teams. Three separate groups hacking away at their own
projects, tossing ideas about and getting input from a few members
upstream, not to mention the whole OLPC offices around the corner- this
was a right proper hackathon, and something that makes me excited for the
future of these projects.&lt;/p&gt;
</summary><category term="peopledashboard"></category><category term="hackathon"></category><category term="widgets"></category><category term="Boston"></category></entry><entry><title>CIVX Stuff</title><link href="http://nathanielca.se/civx/civx-stuff.html" rel="alternate"></link><updated>2010-09-09T18:11:00-04:00</updated><author><name>Nathaniel Case</name></author><id>tag:nathanielca.se,2010-09-09:civx/civx-stuff.html</id><summary type="html">&lt;p&gt;So I've been spending some time finally getting some time to familiarize
myself with CIVX and all the parts that make up the system. I'm almost
comfortable with how the whole thing works together, though I'm not
entirely clear on how some things work to finally get to the screen.&lt;/p&gt;
&lt;p&gt;Still, I got things running, both the current CIVX build and &lt;a class="reference external" href="http://foss.rit.edu/user/17"&gt;Kate's&lt;/a&gt;
widget, though getting the two together is harder than it seems like it
should be. On the other hand, I tweaked the GettingStarted page of the
CIVX wiki to smooth out a few bumps I ran into during the install
process. The Ubuntu instructions are still broken, but I plan going to
look into that in the future.&lt;/p&gt;
&lt;p&gt;In terms of actually getting things done, I haven't done much of
substance. I've been immersing myself in CIVX, git, pep8, and all the
different things that go into the FOSS BOX. While I've been in the open
source community for a while now (and my very first project is almost
1.5 years old), I've never really tried to insert myself into a project
that was running in full swing with established work. Somehow this seems
different than the places I've worked previously... though that could
simply be the distributed nature of the work. With &lt;a class="reference external" href="http://lewk.org"&gt;Luke&lt;/a&gt; no longer
down the hall somewhere, getting information has turned into a more
interesting experience when the necessary parts are in his head.&lt;/p&gt;
&lt;p&gt;I'm looking forward to an exciting next few weeks here, and a fruitful
next few years with the information learned from this experience.&lt;/p&gt;
</summary><category term="peopledashboard"></category><category term="widgets"></category></entry></feed>