<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Why Not Wingnut? - CIVX</title><link href="http://blog.katherineca.se/" rel="alternate"></link><link href="http://blog.katherineca.se/feeds/civx.atom.xml" rel="self"></link><id>http://blog.katherineca.se/</id><updated>2022-12-07T15:55:10-05:00</updated><entry><title>Recent Projects: Knowledge</title><link href="http://blog.katherineca.se/civx/recent-projects-knowledge.html" rel="alternate"></link><published>2012-08-07T23:39:00-04:00</published><updated>2022-12-07T14:07:06-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2012-08-07:/civx/recent-projects-knowledge.html</id><summary type="html">&lt;p&gt;One of the cool features of CIVX that really caught my interest when I
first started working on it was the &lt;a class="reference external" href="https://github.com/FOSSRIT/knowledge"&gt;Knowledge DB&lt;/a&gt;. Using the magic of
Python, Knowledge is a vertical, polymorphic database for storing
knowledge about things, which means very little to anyone, even me.&lt;/p&gt;
&lt;p&gt;What Knowledge does …&lt;/p&gt;</summary><content type="html">&lt;p&gt;One of the cool features of CIVX that really caught my interest when I
first started working on it was the &lt;a class="reference external" href="https://github.com/FOSSRIT/knowledge"&gt;Knowledge DB&lt;/a&gt;. Using the magic of
Python, Knowledge is a vertical, polymorphic database for storing
knowledge about things, which means very little to anyone, even me.&lt;/p&gt;
&lt;p&gt;What Knowledge does is it allows you to store anything (or anything
Python can pickle, at least), as arbitrary collections of Entities and
Facts.&lt;/p&gt;
</content><category term="CIVX"></category><category term="knowledge"></category></entry><entry><title>Multiprocessing the PolyScraper</title><link href="http://blog.katherineca.se/civx/multiprocessing-the-polyscraper.html" rel="alternate"></link><published>2011-06-29T18:04:00-04:00</published><updated>2022-12-07T15:55:10-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2011-06-29:/civx/multiprocessing-the-polyscraper.html</id><summary type="html">&lt;p&gt;Warning: This post was written at 4AM and contains a technical account
of what I have been doing attempting to parallelize CIVX's internals. If
you are looking for a more general overview of what I have been doing
recently, you are better off looking to another one of my posts …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Warning: This post was written at 4AM and contains a technical account
of what I have been doing attempting to parallelize CIVX's internals. If
you are looking for a more general overview of what I have been doing
recently, you are better off looking to another one of my posts.&lt;/p&gt;
&lt;p&gt;Recently, I have been working on CIVX's PolyScraper, a neat little piece
of code designed to be able to read and understand structured text
without knowing how the text is structured beforehand. On Thursday, I
let a test scrape of a rather large dataset start, figuring it would
finish sometime over the weekend and I'd be able to pick it up on
Monday. Then Monday rolled around, and the scrape was still running.&lt;/p&gt;
&lt;p&gt;Worse, it didn't seem to be taking full advantage of the available
resources. Running as it was on the boat, it had four cores at its
disposal, however it was steadfastly using only one core.
Now PolyScraping is not an inherently parallelizable task, but on large
datasets it should benefit from some kind of parallelization,
particularly when using large numbers of small files (less so with small
numbers of large files, those types of tasks are usually sequential as
you have a smaller number of resources blocking on read IO). Clearly
there were other things to look into, but if I could do this, this would
mean a huge win for offline scraping, which was one of the things I had
enabled with my addition of local file support to the PolyScraper.&lt;/p&gt;
&lt;p&gt;This all led me to &lt;a class="reference external" href="http://docs.python.org/library/multiprocessing.html"&gt;multiprocessing&lt;/a&gt;, a library I'd been wanting to try
out in python for some time now. Without going into too much detail,
multiprocessing attempts to get around the &lt;a class="reference external" href="http://docs.python.org/glossary.html#term-global-interpreter-lock"&gt;Global Interpreter Lock&lt;/a&gt; by
spawning subprocesses instead of threads.&lt;/p&gt;
&lt;p&gt;The first attempt was written pretty quickly, as I still remember a lot
from my Parallel Computing class from a while ago. Indeed the main
problem turned out to be SQLAlchemy, or, more specifically our use of
sqlite for a backend db. Sqlite is not the most robust of databases and
can't really handle multiple processes attempting to write to the db at
once. Luke suggested (and I would love to try) moving over to Postgres
as we will eventually be doing on the boat, but unfortunately the boat
has been 'stuck ashore' for some time now due to an extended outage in
CSH's network.&lt;/p&gt;
&lt;p&gt;In the meantime I have been whittling the process down to what I think
is the essentials. In the process I have made a complete mess of the
code concerning the PolyScraper, but I should be able to make things at
least look like the way they were before too long.&lt;/p&gt;
&lt;p&gt;At this point, though, I have been working on this project for close to
20 hours today now. Luke is in town and we're all posted up in Remy's
new place all hacking on our projects together. With any luck a good
night's sleep will clear my head and give me new ideas for tomorrow.&lt;/p&gt;
</content><category term="CIVX"></category><category term="hackathon"></category><category term="SURS"></category><category term="polyscraper"></category></entry><entry><title>Back up to Speed</title><link href="http://blog.katherineca.se/civx/back-up-to-speed.html" rel="alternate"></link><published>2011-06-21T22:56:00-04:00</published><updated>2022-12-07T15:51:45-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2011-06-21:/civx/back-up-to-speed.html</id><summary type="html">&lt;p&gt;I've almost closed &lt;a class="reference external" href="https://fedorahosted.org/civx/ticket/106"&gt;bug #106&lt;/a&gt;. I've done all I can do for now, until I
can figure out how to attribute actions to senators. Until then, I
should comment out the 'actions' tab tomorrow with a note letting
whoever tries this next what I've already tried.&lt;/p&gt;
&lt;p&gt;There is still some …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've almost closed &lt;a class="reference external" href="https://fedorahosted.org/civx/ticket/106"&gt;bug #106&lt;/a&gt;. I've done all I can do for now, until I
can figure out how to attribute actions to senators. Until then, I
should comment out the 'actions' tab tomorrow with a note letting
whoever tries this next what I've already tried.&lt;/p&gt;
&lt;p&gt;There is still some work to do in this code, particularly with fixing
the hacky Assembly scraping I wrote last year which also broke. However,
considering that the Assembly is not currently one of the bits we are
trying to expose (and they don't have a nice public API like the
Senate), it probably won't get done for a little while.&lt;/p&gt;
&lt;p&gt;When I left yesterday, I had exposed the senator's social page, but none
of the other tabs were showing up. The problem for this turned out to be
that the image representing the tab was corrupted and the text beneath
it was white, making it overall look like the tab was invisible. Once I
got a new image for the tab, they all suddenly appeared, though only the
bills had any information.&lt;/p&gt;
&lt;p&gt;The next thing to fix was the scraping of the committees, whose pages
had also changed subtly in the past few months. Fixing this was much
less annoying than building them the first time, and I was able to
remove a lot of old shims in the code from when I was first being
introduced to &lt;a class="reference external" href="http://www.crummy.com/software/BeautifulSoup/"&gt;BeautifulSoup&lt;/a&gt;. Some of my later changes made this
particularly easy, and since BeautifulSoup is so powerful, I was able to
restore access to the data with relative ease. As a bonus, as soon as I
had committees back up, the tabs for votes and meetings came with it for
free. Suddenly, I was almost there!&lt;/p&gt;
&lt;p&gt;The final problem I encountered today is actually not a new one, but one
we struggled with last year, and one I now feel confident I have
actually fixed and understand now. Once I got all the data pulling
again, a few of the pages would crash the server with
UnicodeDecodeErrors.&lt;/p&gt;
&lt;p&gt;As a warning, some heavy Python is about to come down
UnicodeDecodeError is an error which happens (generally) when attempting
to decode a string into a Unicode object. This is generally a great
thing to do, as Python strings are generally encoded in the relatively
restrictive ASCII, which does not have characters for any of the more
exciting characters like accents and non-latin symbols. Unicode has no
such restrictions, and indeed has data for many, many more symbols, at
the cost of a few more bits of storage per character.
So why were we getting this error? The relevant line of code was 's =
unicode(s)' and was contained within &lt;a class="reference external" href="http://pythonpaste.org/webob/#introduction"&gt;WebOb&lt;/a&gt; code, not something I was
going to be able to modify successfully. Still, even this shouldn't be a
problem. The purpose of this function is to turn strings to Unicode
strings.&lt;/p&gt;
&lt;p&gt;Except I didn't have a string, I already had a Unicode string.
Even this shouldn't be a problem, except that unicode() tries to
interpret its input as a string and then turn it into a Unicode string.
And while Unicode strings can be easily represented as normal strings,
the default of the unicode() function is to try to interpret those
strings as ASCII strings, and I had accents in the strings. These
strings were representing the names of the senators, so I had to make
sure it came out right.&lt;/p&gt;
&lt;p&gt;In order to solve this, I had to reversibly represent these names as a
sequence of ASCII characters.&lt;/p&gt;
&lt;p&gt;There are a few ways to replace out-of-bound characters when changing
strings into lesser encodings, and I had two useful ones to chose from.
The obvious one to chose was to change the characters into XML character
entities, however this quickly turned out to be insufficient. While
&amp;amp;#233; correctly showed up as é on the page, this string is used to
represent the name everywhere, including in the internal URL
representing the page. And the ampersand was quickly stripped out as a
broken argument to the URL, leading to a page for a nonexistent Senator.
Looking through the code, there were three distinct uses for the name
string. The first, which had started all this, was as an ASCII key to a
dictionary which needed to be authoritative but not necessarily
accurate. In other words, I needed it to be the same everywhere, but it
didn't necessarily need to be the correct name of the senator. The
second was the use on the generated web page, which needed to be as
accurate as possible to the Senator's actual name, as it is going to be
viewed publicly. The third, and the current stickler was the name in the
URL. Again, this had to be authoritative but not necessarily accurate.
This one, however, had to also only include web-safe characters, of
which &amp;amp;, # and ; do not qualify.&lt;/p&gt;
&lt;p&gt;I mulled this over for a while, thinking up more and more elaborate
schemes for intercepting the names before they reached critical areas,
but none of it was terribly good coding practice. After far too much
thinking, I realized the obvious answer: have separate internal and
external names. The system still relies on the senator's name, which is
still a questionable practice given the multiple spellings of names that
occasionally pop up, (but mostly because I remember &lt;a class="reference external" href="http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/"&gt;this post&lt;/a&gt;, which
is something you should always keep in mind when programming around
names. The display name, on the other hand, has none of the restrictions
on characters (though it still needs to be ASCII to display properly),
but by using XML entities, we can make any character we want without
problems.&lt;/p&gt;
&lt;p&gt;This was a long path to take to get back to where we were, but I think
that I really understand Python's Unicode in a way I never grasped
before. This should definitely help in the future as Unicode is a very
important part of coding portable applications and that's something I
want to do.&lt;/p&gt;
</content><category term="CIVX"></category><category term="peopledashboard"></category><category term="widgets"></category><category term="scrapers"></category><category term="SURS"></category></entry><entry><title>Shelves and Shoves</title><link href="http://blog.katherineca.se/civx/shelves-and-shoves.html" rel="alternate"></link><published>2011-06-21T22:56:00-04:00</published><updated>2022-12-07T15:52:26-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2011-06-21:/civx/shelves-and-shoves.html</id><summary type="html">&lt;p&gt;Today is the day to hit &lt;a class="reference external" href="https://fedorahosted.org/civx/ticket/105"&gt;bug #105&lt;/a&gt;, another of the leftover bugs from
last year.&lt;/p&gt;
&lt;p&gt;The story goes something like this: there's a lot of data on
nysenate.gov that is nice to have, but asking for that info on every
call is a little cumbersome. We want to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today is the day to hit &lt;a class="reference external" href="https://fedorahosted.org/civx/ticket/105"&gt;bug #105&lt;/a&gt;, another of the leftover bugs from
last year.&lt;/p&gt;
&lt;p&gt;The story goes something like this: there's a lot of data on
nysenate.gov that is nice to have, but asking for that info on every
call is a little cumbersome. We want to cache as much of the data as we
can, particularly the stuff that's not going to change in the next week
or longer. Previously, I had implemented a simple pylons cache which was
fast, but had no persistent storage, so every time the server went down
it pulled all the info again. And due to the way the scrape was written,
it pulled all the info for all the senators at once, creating quite a
bit of lag before the first page showed up. This clearly wasn't going to
be something we could continue to develop with.&lt;/p&gt;
&lt;p&gt;Now, I know nothing about caching data, so I did some poking around in
CIVX to see how it is done elsewhere. Most of the other caches I found
in CIVX code were related to caching text feeds, which were not as
explanatory as I was hoping. Once I felt I had a handle on how things
were done there, I began to try to implement some of it, only to be
shown &lt;a class="reference external" href="http://threebean.wordpress.com/2011/06/08/cached-function-calls-with-expiration-in-python-with-shelve-and-decorator/"&gt;this post&lt;/a&gt; on &lt;a class="reference external" href="http://docs.python.org/library/shelve.html"&gt;shelve&lt;/a&gt;, a Python library for storing arbitrary
data. Combined with the decorator, this seemed to do exactly what I
wanted, namely provide a permanent storage area for a bunch of data with
a configurable expire time. I dumped the code into the dashboard, hooked
the proper inputs up and let it run. The results were... promising, but
not astonishing. The file storage worked, once the data was cached, we
stopped looking to nysenate.gov for data and instead used our own data,
even after server restarts.&lt;/p&gt;
&lt;p&gt;The problem was that the file storage seemed to be slower than the
previous memory cache. This is all perfectly reasonable, since disk
access is much slower than memory, and a lot of data has to get pulled
for each senator. The first obvious thing I could do is to re-enable the
memory cache, but this did not seem to help as much as I wanted it to.
At this point, &lt;a class="reference external" href="lewk.org"&gt;Luke&lt;/a&gt; popped up in chat to sat that Moksha had a
&lt;a class="reference external" href="http://pypi.python.org/pypi/shove"&gt;Shove&lt;/a&gt; cache it uses for feeds. Sure enough, back in the files I had
been poking through earlier, there were some references to Shove. Back to
the net, I started to explore what Shove was and how it could help me.
It turns out Shove is mostly drop in compatible with shelve, and aims to
be a more extensible replacement for it. Once I got a handle on how
Shove works differently from shelve (answer, not very), I made a few
tiny tweaks and got a version successfully working with Shove and a
sqlite backend. This didn't make the end result any faster (well maybe a
little, but not much), but there is a lot of room for improvement,
particularly if I can hook into Moksha's own stores. Further, Shove has
its own abilities to cache items in memory in addition to storing them,
which I would like to look into. The best route for efficiencies, I
think is to change how the data gets stored in the cache. Currently all
the data gets pulled at once, which was done to pacify the pylons cache.
However, if I can get individual caches for each senator, then I can
pull smaller volumes of data at a time, hopefully speeding up the
process.&lt;/p&gt;
&lt;p&gt;We'll see where I get tomorrow, but so far I'm feeling pretty good about
all this.&lt;/p&gt;
</content><category term="CIVX"></category><category term="peopledashboard"></category><category term="widgets"></category><category term="scrapers"></category><category term="SURS"></category></entry><entry><title>Summer of CIVX</title><link href="http://blog.katherineca.se/civx/summer-of-civx.html" rel="alternate"></link><published>2011-06-21T22:56:00-04:00</published><updated>2022-12-07T15:52:57-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2011-06-21:/civx/summer-of-civx.html</id><summary type="html">&lt;p&gt;So I'm back at RIT for the summer working on CIVX again. There's been a
lot of development on Moksha, the software stack CIVX runs on, and not
all of it was a trivial update. Still, many of the problems I
encountered were definitely my fault, not the least of …&lt;/p&gt;</summary><content type="html">&lt;p&gt;So I'm back at RIT for the summer working on CIVX again. There's been a
lot of development on Moksha, the software stack CIVX runs on, and not
all of it was a trivial update. Still, many of the problems I
encountered were definitely my fault, not the least of which was
forgetting Arch Linux has switched to Python 3.&lt;/p&gt;
&lt;p&gt;Once I was up, I looked into fixing the people dashboard we worked on
last summer. In the meantime, the NYS Senate updated their API for
getting open government data, so I had to figure out the new scheme and
try to make it work. Complicating this is that they still don't have
easy access to grabbing all the current senators, and the page we look
at to get this information changed enough to stop the script from
completing.&lt;/p&gt;
&lt;p&gt;I'm actually surprised how quickly I was able to work this out, though
of course this is not even remotely new to me. But despite nearly a year
of inactivity on the project I seem to have gotten back into the swing
of it pretty well.&lt;/p&gt;
</content><category term="CIVX"></category><category term="peopledashboard"></category><category term="widgets"></category><category term="SURS"></category></entry><entry><title>The Last Week</title><link href="http://blog.katherineca.se/civx/the-last-week.html" rel="alternate"></link><published>2011-06-21T22:56:00-04:00</published><updated>2022-12-07T15:53:22-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2011-06-21:/civx/the-last-week.html</id><summary type="html">&lt;p&gt;This week has been a mess for a lot of reasons. Let's see what I managed
to get through so far.&lt;/p&gt;
&lt;p&gt;One of the things I got to look at this week is threebean's mokshactl
branch of CIVX and Moksha. This is a project to simplify the
administration of a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week has been a mess for a lot of reasons. Let's see what I managed
to get through so far.&lt;/p&gt;
&lt;p&gt;One of the things I got to look at this week is threebean's mokshactl
branch of CIVX and Moksha. This is a project to simplify the
administration of a Moksha installation. The project grew out of an
attempt to easily package Moksha and grew into a much larger system
capable of managing most aspects of CIVX at once, and in a very pretty
package, too. It has a few problems, but for the most part, it performs
quite well, and best of all, it will even integrate itself with Moksha,
controlling the necessary aspects of Moksha as well.&lt;/p&gt;
&lt;p&gt;In less exciting news, I poked around in the people dashboard while I
had some time and got Assembly members working again. It didn't take
much as I had expected, but served to keep me on task while Remy was in
one of the never ending series of meetings he's had this week.
On a lighter side of things, I put some &lt;a class="reference external" href="http://lobstertech.com/fabulous.html"&gt;fabulous&lt;/a&gt; in the CIVX shell
today as I was working in it. The mokshactl branch is already
fabuloused, and once you see that, there's no coming back. fabulous
makes things very pretty with only a little work.&lt;/p&gt;
&lt;p&gt;Other than that not a lot has gone down. Some work has gone into the
polyscraper, but that's nothing worth mentioning at this point. Between
that and some internal matters and hours of meetings and my car
developing a leak in it's brake line, that's all that went down this
week. Tomorrow I get to drive home and hopefully fix my car properly.&lt;/p&gt;
</content><category term="CIVX"></category><category term="peopledashboard"></category><category term="widgets"></category><category term="scrapers"></category><category term="SURS"></category><category term="fabulous"></category></entry><entry><title>Grokking the Core</title><link href="http://blog.katherineca.se/civx/grokking-the-core.html" rel="alternate"></link><published>2011-06-21T22:55:00-04:00</published><updated>2022-12-07T15:53:48-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2011-06-21:/civx/grokking-the-core.html</id><summary type="html">&lt;p&gt;This week begins the real dive into the core of what makes CIVX. Today
(and yesterday, though yesterday hardly counts as a real day) were spent
adding major functionality to the polyscraper, something that's been
overdue for a long time now.&lt;/p&gt;
&lt;p&gt;But what is this magical polyscraper? Well, in short …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week begins the real dive into the core of what makes CIVX. Today
(and yesterday, though yesterday hardly counts as a real day) were spent
adding major functionality to the polyscraper, something that's been
overdue for a long time now.&lt;/p&gt;
&lt;p&gt;But what is this magical polyscraper? Well, in short, it's magic. A lot
of magic, actually, and that's half the problem. You see, in ye olden
days of CIVX, each data source had to have its own scraper, and these
were called whenever CIVX decided its data was old enough to get shoved
out and replaced with new data. This was all well and fine, except that
it took a very long time to get a scraper written for a new data source.
You would have to define all the columns, give it a location to look,
make sure you understood the site's particular dialect and scrubbed out
any irregularities in their data. What the poly scraper does is it
replaces all of those individual scrapers and replaces them with one big
scraper which is smart enough to deal with any URL it finds.&lt;/p&gt;
&lt;p&gt;What I've been doing is adding new sources of data to the polyscraper.
In particular, yesterday was spent adding the ability to read files off
of a local disk and properly store them. This, in turn, exposed a few
holes in the underlying framework which needed to be patched. However,
this is a vitally important function, as things like the SunlightNY
scraper I wrote last year works outside of CIVX proper (in Java, no
less) and cannot be thrown into the polyscraper as easily. But I can
download the files locally, and then work on them when it is convenient.
With proper message passing, I can even seamlessly tell the polyscraper
to pick up the files as soon as they are downloaded.&lt;/p&gt;
&lt;p&gt;Previously to this I had been working at the periphery of CIVX, adding
functionality to widgets and individual scrapers. This is my first real
push into the core functionality of CIVX, and it is good to see that I
really have picked enough up in all this time to really start to
understand the underlying structure of everything. Every day I learn
more about what goes on inside this machine, and every day marks another
set of tools I've learned to wield. I can't wait to see how far I get by
the end of the summer.&lt;/p&gt;
</content><category term="CIVX"></category><category term="scrapers"></category><category term="SURS"></category><category term="polyscraper"></category></entry><entry><title>Boston</title><link href="http://blog.katherineca.se/civx/boston.html" rel="alternate"></link><published>2011-01-23T07:14:00-05:00</published><updated>2022-12-07T15:45:11-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2011-01-23:/civx/boston.html</id><summary type="html">&lt;p&gt;So here we are in OLPC HQ, right in the middle of MIT. It's pretty sweet
having &lt;a class="reference external" href="http://lewk.org/"&gt;Luke&lt;/a&gt; around again to hack CIVX with us.&lt;/p&gt;
&lt;p&gt;I've had a lot to do in the past few days. Remy's been showing me
scrapers and models, and I've been helping transition &lt;a class="reference external" href="http://foss.rit.edu/user/17"&gt;Kate's&lt;/a&gt; people …&lt;/p&gt;</summary><content type="html">&lt;p&gt;So here we are in OLPC HQ, right in the middle of MIT. It's pretty sweet
having &lt;a class="reference external" href="http://lewk.org/"&gt;Luke&lt;/a&gt; around again to hack CIVX with us.&lt;/p&gt;
&lt;p&gt;I've had a lot to do in the past few days. Remy's been showing me
scrapers and models, and I've been helping transition &lt;a class="reference external" href="http://foss.rit.edu/user/17"&gt;Kate's&lt;/a&gt; people
dashboard into an integrated component or integrating &lt;a class="reference external" href="http://rebeccanatalie.com/"&gt;Rebecca's&lt;/a&gt; theme
changes on the side. It's been hectic and fun and tough, but I finally
feel like I'm contributing to a project, something with substance and
goals, not just writing code to accomplish a task like some of my
previous co-ops. Being in a team this large helps, especially when we
pull in outside help like Luke, but I think it's mainly Remy's
infectious excitement for the project. When he gets down to work, one
can't help but feel his vision and be excited for the possibilities.&lt;/p&gt;
&lt;p&gt;Unfortunately, that means I had precious little time to pay attention to
the other teams. Three separate groups hacking away at their own
projects, tossing ideas about and getting input from a few members
upstream, not to mention the whole OLPC offices around the corner- this
was a right proper hackathon, and something that makes me excited for the
future of these projects.&lt;/p&gt;
</content><category term="CIVX"></category><category term="peopledashboard"></category><category term="hackathon"></category><category term="widgets"></category><category term="Boston"></category></entry><entry><title>Almost There...</title><link href="http://blog.katherineca.se/civx/almost-there.html" rel="alternate"></link><published>2010-09-09T18:11:00-04:00</published><updated>2022-12-07T14:07:06-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2010-09-09:/civx/almost-there.html</id><summary type="html">&lt;p&gt;Today I worked my way through more of &lt;a class="reference external" href="http://rebeccanatalie.com"&gt;Rebecca's&lt;/a&gt; changes to the people
dashboard. It was actually in better condition than I had thought last
night. The first tab was the only one with the majority of the changes,
and most of the changes were easily applied once I understood …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I worked my way through more of &lt;a class="reference external" href="http://rebeccanatalie.com"&gt;Rebecca's&lt;/a&gt; changes to the people
dashboard. It was actually in better condition than I had thought last
night. The first tab was the only one with the majority of the changes,
and most of the changes were easily applied once I understood them-
which is what I spent hours yesterday trying to do.&lt;/p&gt;
&lt;p&gt;I have a problem with writing quantities of HTML because they end up as
giant messes. Even XHTML strict isn't enough for me, though it does come
closer. Invariably, any file of reasonable complexity is going to have
whitespace inconsistencies, mislaid elements, or even entire sections
forgotten. This morning I took a fresh look at the generated HTML and
dashboard.mak and tried simply to understand their structure. After
really getting into the template version, I began to see what was really
necessary and not from Rebecca's blinged up copy. There are still a few
bits missing from the final version, but I think I can get them nailed
down before I leave today.&lt;/p&gt;
</content><category term="CIVX"></category><category term="peopledashboard"></category></entry><entry><title>CIVX Stuff</title><link href="http://blog.katherineca.se/civx/civx-stuff.html" rel="alternate"></link><published>2010-09-09T18:11:00-04:00</published><updated>2022-12-07T14:07:06-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2010-09-09:/civx/civx-stuff.html</id><summary type="html">&lt;p&gt;So I've been spending some time finally getting some time to familiarize
myself with CIVX and all the parts that make up the system. I'm almost
comfortable with how the whole thing works together, though I'm not
entirely clear on how some things work to finally get to the screen …&lt;/p&gt;</summary><content type="html">&lt;p&gt;So I've been spending some time finally getting some time to familiarize
myself with CIVX and all the parts that make up the system. I'm almost
comfortable with how the whole thing works together, though I'm not
entirely clear on how some things work to finally get to the screen.&lt;/p&gt;
&lt;p&gt;Still, I got things running, both the current CIVX build and &lt;a class="reference external" href="http://foss.rit.edu/user/17"&gt;Kate's&lt;/a&gt;
widget, though getting the two together is harder than it seems like it
should be. On the other hand, I tweaked the GettingStarted page of the
CIVX wiki to smooth out a few bumps I ran into during the install
process. The Ubuntu instructions are still broken, but I plan going to
look into that in the future.&lt;/p&gt;
&lt;p&gt;In terms of actually getting things done, I haven't done much of
substance. I've been immersing myself in CIVX, git, pep8, and all the
different things that go into the FOSS BOX. While I've been in the open
source community for a while now (and my very first project is almost
1.5 years old), I've never really tried to insert myself into a project
that was running in full swing with established work. Somehow this seems
different than the places I've worked previously... though that could
simply be the distributed nature of the work. With &lt;a class="reference external" href="http://lewk.org"&gt;Luke&lt;/a&gt; no longer
down the hall somewhere, getting information has turned into a more
interesting experience when the necessary parts are in his head.&lt;/p&gt;
&lt;p&gt;I'm looking forward to an exciting next few weeks here, and a fruitful
next few years with the information learned from this experience.&lt;/p&gt;
</content><category term="CIVX"></category><category term="peopledashboard"></category><category term="widgets"></category></entry><entry><title>Here be Dragons</title><link href="http://blog.katherineca.se/civx/here-be-dragons.html" rel="alternate"></link><published>2010-09-09T18:11:00-04:00</published><updated>2022-12-07T15:30:46-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2010-09-09:/civx/here-be-dragons.html</id><summary type="html">&lt;p&gt;Today was the day we got &lt;a class="reference external" href="http://www.rebeccanatalie.com"&gt;Rebecca&lt;/a&gt; on to a git repo towards
implementing her changes to the people dashboard. It's only a halfway
step, as she isn't entirely using the proper version of the widgets but
a hacked one that works locally, and needs to be morphed into something …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today was the day we got &lt;a class="reference external" href="http://www.rebeccanatalie.com"&gt;Rebecca&lt;/a&gt; on to a git repo towards
implementing her changes to the people dashboard. It's only a halfway
step, as she isn't entirely using the proper version of the widgets but
a hacked one that works locally, and needs to be morphed into something
that will work in the context of the CIVX stack. Hopefully soon she will
be up to speed and be able to make a more direct submission in the near
future.&lt;/p&gt;
&lt;p&gt;As it stands, this is good stuff, and the end result is definitely
usable, even if it's not in the format we want it just yet. Translating
one to the other has proven tiresome as well; I spent the better part of
three hours just to clean up the first of our tabs. There are a few
items I think might not be translatable, things that mainly live in
Moksha, but we'll get to that when we get to that. Right now, I need a
graphical diff viewer that cares neither for whitespace nor line breaks,
just for what's in the code. Good old meld, which I had been using, has
proven itself inadequate to the massive differences between these files.
Hopefully tomorrow I will have a fresh start from which to sculpt this
mess I've constructed into its completed form.&lt;/p&gt;
</content><category term="CIVX"></category><category term="peopledashboard"></category></entry><entry><title>Just another ten-hour day</title><link href="http://blog.katherineca.se/civx/just-another-ten-hour-day.html" rel="alternate"></link><published>2010-09-09T18:11:00-04:00</published><updated>2022-12-07T14:07:06-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2010-09-09:/civx/just-another-ten-hour-day.html</id><summary type="html">&lt;p&gt;Today was another exciting day in CIVX-land.&lt;/p&gt;
&lt;p&gt;tl;dr: I spend the day helping other people and being awesome
It started out with the latest in a series of attempts at getting
&lt;a class="reference external" href="http://www.rebeccanatalie.com"&gt;Rebecca&lt;/a&gt; to a working CIVX repo. As I work through this with her, I am
slowly working out …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today was another exciting day in CIVX-land.&lt;/p&gt;
&lt;p&gt;tl;dr: I spend the day helping other people and being awesome
It started out with the latest in a series of attempts at getting
&lt;a class="reference external" href="http://www.rebeccanatalie.com"&gt;Rebecca&lt;/a&gt; to a working CIVX repo. As I work through this with her, I am
slowly working out how all this works together (though admittedly it is
largely me flailing while Rebecca watches). With &lt;a class="reference external" href="http://lewk.org"&gt;Luke's&lt;/a&gt; help, I
eventually realized that the only thing really needed for CIVX to run is
python-virtualenv (it can run without, but that involves actually
installing python packages to /usr/local, something generally undesired
for a development environment). After some question of whether Rebecca
had sudo permission, we eventually discovered she did, and a short sudo
easy_install virtualenv later, we were ready to start installing the
CIVX stack.&lt;/p&gt;
&lt;p&gt;If you haven't read the &lt;a class="reference external" href="https://fedorahosted.org/civx/wiki/Setup"&gt;CIVX developer's guide&lt;/a&gt; (and I think it's
probably safe to assume you haven't), it's a bit of a mess. Not actually
bad, but short and disorganized. This isn't too bad when you've got a
small, fairly tight development group with the main brain usually a ping
away on IRC, but as people are finding CIVX, I have taken it upon myself
to document every bump in my path. When I was first thrust into CIVX,
the page was much sparser with less detail and fewer sections, I have
added areas whenever there was a question of how to do what that
eventually came down to 'ask Luke'. Any time an arcane set of commands
came up I tried to get them on the page with as much information as I
could figure out, hopefully someone will take pity on my notes and make
them more descriptive.&lt;/p&gt;
&lt;p&gt;Around this time &lt;a class="reference external" href="http://foss.rit.edu/user/17"&gt;Kate&lt;/a&gt; also had a few questions for me, most of which
I could figure out. However, I was still trying to get Rebecca running
and hadn't even touched my own computer more than to turn on IRC and
look a few thins up for Rebecca. Kate was having some trouble as she was
trying to scrape information off the NYS Senate page of senators,
neither of which I had done before. Rebecca had other things to do, and
getting her Mac up to speed was a lot of wait and pray so I switched
over to Kate's task. Now Kate also has a Mac, but she was set up with
CIVX long ago and could never quite explain to me how, thanks again to
arcane commands.&lt;/p&gt;
&lt;p&gt;Anyway, her task involved a particular Unicode character in a senator's
name not playing well with her scraped name-to-URL converter magic.
Having only last night read &lt;a class="reference external" href="http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/"&gt;Falsehoods Programmers Believe About
Names&lt;/a&gt; off StumbleUpon, I immediately recognized this way as a dead
end. Sure, you could force all the current names into this pattern, but
it would never last. Some day, a senator would show up such that the
senate's conversion script and ours didn't match, and then that senator
would disappear from CIVX. After a bit of poking, however, I found that
each senator had a link to their contact page right in the div we were
scraping. A bit of poking around later, and I had a 100% reliable link
to each senator's page, as verified by the senate themselves. Suddenly
every senator's page worked, without any of this needless mucking about
in Unicode transformations.&lt;/p&gt;
&lt;p&gt;Which brought us to our second problem. Most (with one important
exception) senators have a page hosted on &lt;a class="reference external" href="http://www.nysenate.gov"&gt;http://www.nysenate.gov&lt;/a&gt;, and
most have a contact page at /senators/first-m-last/contact.
What that page contains, however, seems largely up to each senator. Kate
had (and was quite proud of) her 4-line, incredibly complex and
unmaintainable regular expression which she used to mangle each page
into a regular form. However, as we poked further and further, we found
more and more inconsistencies and exceptions to the regular expression.
Clearly this was completely the wrong way again, but what was the right
way.&lt;/p&gt;
&lt;p&gt;I suddenly saw an interesting anomaly. Most senators had the contact
info were styled exactly the same, despite having quite varying styles
otherwise. Kate had already seen that most of the addresses are together
in some sort of paragraph tag, and was trying to regexp on the contents
of each paragraph on the page. What she hadn't noticed was that every
page had a &amp;lt;div class=&amp;quot;field-content&amp;quot;&amp;gt; that contained all the contact
info. Now that, that was something a bit more to go on. Furthermore,
this contained all the contact info- occasionally more, but always the
minimum was their District Office and their Albany Office. Furthermore,
it was already in some form of HTML, which Kate had previously been
stripping and rebuilding manually. If we simply took this HTML as-is and
plugged it into CIVX's contact page, instantly every senator had exactly
what we (and they) wanted!&lt;/p&gt;
&lt;p&gt;Well, almost.&lt;/p&gt;
&lt;p&gt;It was about at this point that Rebecca went home for the day, CIVX not
yet working. a few important packages were missing from &lt;a class="reference external" href="http://pypi.python.org/pypi"&gt;pypi&lt;/a&gt;, keeping
us from completing the CIVX setup step so she could get cracking on real
CIVX, without needing me to merge every change she wanted to push. Still
this left me with more time to work on the regular expressions.&lt;/p&gt;
&lt;p&gt;Now, most senators worked flawlessly, with two obvious exceptions. the
first, and the one I didn't want to tackle just yet, was the senator I
mentioned briefly above, the page of &lt;a class="reference external" href="http://www.kemphannon.com/"&gt;Sen. Kemp Hannon&lt;/a&gt;. Notice
anything different about his page? Well, for one, it's not hosted on
nysenate.gov, and for another, he has no explicit contact page. The
first made our scraper entirely useless without coding in an exception
for senators with separate websites, and the second made such an
exception next to impossible to make general, without reverting back to
the 'check each paragraph for addresses' method.&lt;/p&gt;
&lt;p&gt;So Kemp was put on the backburner for now. The other one, which failed
somewhat more spectacularly, didn't even break. Rather, the contact page
of &lt;a class="reference external" href="http://www.nysenate.gov/senator/john-j-flanagan/contact"&gt;Sen. John J. Flanagan&lt;/a&gt;. Putting aside for the moment the excess
content in the div, including the NYS seal, and a few lines about
contact information, this is the worst example against automatically
generated HTML I have had the misfortune of needing to scrape.&lt;/p&gt;
&lt;p&gt;Problem 1: &amp;lt;p &amp;gt;&amp;amp;nbsp;&amp;lt;p /&amp;gt;&amp;lt;br /&amp;gt; I kid you not, this is on the page a
minimum of 20 times in a row so that his Albany Office is so far below
the fold so as to be nonexistent. Sometimes there's inline styles,
sometimes not. One line has a simple space character instead of the
edgier, hipper &amp;amp;nbsp;. I wanted them all gone.this resulted in five
separate regexps so python wouldn't get too greedy and remove all the
content. One to replace &amp;amp;nbsp; with ' ', another to remove all
whitespace between a closing angle bracket and an opening one, a third
to remove anything matching style=&amp;quot;*&amp;quot;, a fourth to remove all the (now)
empty paragraphs, and a fifth and final one to turn any group of two or
more consecutive break tags into a single tag. It is probably fortunate
that python would not correctly apply my first attempt which was far
less readable, and more of a one-liner, as I don't know if I could have
understood it now had I not broken it into its component parts.
Problem 2 is a bit more of a WTF moment, both beautiful and frightening,
so I will reproduce it here verbatim:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;lt;P style=&amp;quot;TEXT-ALIGN: center&amp;quot;&amp;gt;&amp;lt;SPAN style=&amp;quot;COLOR: #012849; FONT-SIZE:
18pt&amp;quot;&amp;gt;&amp;lt;SPAN&amp;gt;&amp;lt;SPAN&amp;gt;&amp;lt;SPAN style=&amp;quot;LINE-HEIGHT: 115%; FONT-FAMILY:
'Calibri', 'sans-serif'; COLOR: #012849; FONT-SIZE: 16pt;
mso-fareast-font-family: Calibri; mso-ascii-theme-font: minor-latin;
mso-fareast-theme-font: minor-latin; mso-hansi-theme-font: minor-latin;
mso-bidi-font-family: 'Times New Roman'; mso-bidi-theme-font:
minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: EN-US;
mso-bidi-language: AR-SA&amp;quot;&amp;gt;&amp;lt;SPAN&amp;gt;&amp;lt;STRONG&amp;gt;&amp;lt;SPAN style=&amp;quot;FONT-FAMILY: Times
New Roman&amp;quot;&amp;gt;District Office&amp;lt;BR /&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;SPAN
style=&amp;quot;COLOR: #012849; FONT-SIZE: 16pt&amp;quot;&amp;gt;&amp;lt;SPAN style=&amp;quot;FONT-FAMILY: Times
New Roman&amp;quot;&amp;gt;260 Middle Country Road, Suite 203&amp;lt;BR /&amp;gt;Smithtown, New York
11787&amp;lt;BR /&amp;gt;631-361-2154&amp;lt;BR /&amp;gt;631-361-5367
FAX&amp;lt;/span&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/span&amp;gt;
&lt;/pre&gt;
&lt;p&gt;For those of you following along at home, that's
P(text-align) &amp;gt; SPAN(color, font-size) &amp;gt; SPAN &amp;gt; SPAN &amp;gt; SPAN(line-height,
font-family, color, font-size, a bunch of other font styles) &amp;gt;
SPAN &amp;gt; STRONG &amp;gt; SPAN(font-family) &amp;gt;
SPAN(color, font-size) &amp;gt; SPAN(font-family)&lt;/p&gt;
&lt;p&gt;Naturally, my first order of business was to remove every single span
from the HTML we take in. Because, frankly, this is preposterous. We
already (by problem 1) strip out all the style information, because
frankly, we don't need it, so this mess just turns into six nested
spans, not a very useful thing. Suddenly, the HTML coming out of the
sanitizer is much more compact, and not just because of all the breaks
and paragraphs I took out.&lt;/p&gt;
&lt;p&gt;By the time I finished with this, it was about an hour after most
everyone else had left. I spent the next half hour checking that my
sanitizer didn't break existing pages (it did, but only minorly) and
making sure my code was legible.&lt;/p&gt;
&lt;p&gt;At that point, almost ten hours after I had started, I sat back,
committed my final changes, and decompressed. *This*- this is why I
love open source.&lt;/p&gt;
</content><category term="CIVX"></category><category term="peopledashboard"></category><category term="wat"></category></entry><entry><title>Diving Deep</title><link href="http://blog.katherineca.se/civx/diving-deep.html" rel="alternate"></link><published>2010-06-30T16:55:00-04:00</published><updated>2022-12-07T14:07:06-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2010-06-30:/civx/diving-deep.html</id><summary type="html">&lt;p&gt;Yesterday had been spent working on a proper dev branch to CIVX. Today
we gave it a home.&lt;/p&gt;
&lt;p&gt;Today started off trying to get the current dev CIVX running on our
server. Now, I had some experience setting up a CIVX instance from
getting one running on my box, but …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Yesterday had been spent working on a proper dev branch to CIVX. Today
we gave it a home.&lt;/p&gt;
&lt;p&gt;Today started off trying to get the current dev CIVX running on our
server. Now, I had some experience setting up a CIVX instance from
getting one running on my box, but my box is mine and I know what's on
it. This server is not, so we had a few troubles along the way. Once
again the instructions proved insufficient (though not actually bad per
se). The server was running Python 2.4 by default, and one of the
scripts wanted to be run from Python 2.6, as it was pulling a few things
from future. Remy and I spent more than a little while wondering why
things weren't happening properly when we had neglected to run a command
or two. &lt;a class="reference external" href="&amp;quot;http://lewk.org"&gt;Luke&lt;/a&gt; set us straight at every turn, and I can now say that I
actually understand what most of those commands do with respect to the
rest of the system.&lt;/p&gt;
&lt;p&gt;The second half of the day was a bit more interesting. Once CIVX was
running, my attention was turned to the scrapers. Most of the scrapers
are v2 scrapers, and one of our tasks for the summer is to get things
running up to v3. On the first try getting the stimulus watcher scraper
running, we had a few problems remembering where everything went and
where to call what when. On the second shot getting a scraper for
howdtheyvote.ca data, it went much faster. I need to remember to source
tg2env when I'm on the server, but mostly, things were good today.
Tomorrow we put together the pieces of v3, and keep on moving towards
our goals.&lt;/p&gt;
</content><category term="CIVX"></category><category term="scrapers"></category></entry><entry><title>More Conference Calls</title><link href="http://blog.katherineca.se/civx/more-conference-calls.html" rel="alternate"></link><published>2010-06-24T12:10:00-04:00</published><updated>2022-12-07T14:07:06-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2010-06-24:/civx/more-conference-calls.html</id><summary type="html">&lt;p&gt;Every time I go through one of these calls I feel like I come out
knowing less about the topic discussed. The topics aren't hard, and I
can now follow along and understand most of what they're talking about,
but most of the technologies are things I haven't really looked …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Every time I go through one of these calls I feel like I come out
knowing less about the topic discussed. The topics aren't hard, and I
can now follow along and understand most of what they're talking about,
but most of the technologies are things I haven't really looked at
before. It's interesting, and it's exciting, but it's a little wearying
too. The majority of the talks seem to revolve around the use of Amazon
EC2 instances, of which I know nothing.&lt;/p&gt;
&lt;p&gt;On my own tasks, the semifinal versions of the getall script and the
associated documentation got pushed to &lt;a class="reference external" href="http://bitbucket.org/slinkp/geowebdns"&gt;geowebdns&lt;/a&gt;' repository today. I
feel pretty good about the changes I made, even if it doesn't prove
useful to the current task, I have opened up some small part of someone
else's open source program, and that's really cool.&lt;/p&gt;
</content><category term="CIVX"></category><category term="democracymap"></category><category term="geowebdns"></category></entry><entry><title>Introducing: GeoPirate!</title><link href="http://blog.katherineca.se/civx/introducing-geopirate.html" rel="alternate"></link><published>2010-06-23T07:15:00-04:00</published><updated>2022-12-07T14:07:06-05:00</updated><author><name>Katherine Case</name></author><id>tag:blog.katherineca.se,2010-06-23:/civx/introducing-geopirate.html</id><summary type="html">&lt;p&gt;So I've received my apparently mandated CIVX nickname, despite it
possibly being inaccurate in a week or two. I, along with &lt;a class="reference external" href="http://rebeccanatalie.com/"&gt;Pixel Ninja&lt;/a&gt;
and &lt;a class="reference external" href="http://foss.rit.edu/user/17"&gt;Python Princess&lt;/a&gt;, have been hacking away at our various tasks
together for over a week now, and despite the seemingly constant moving
from place to place …&lt;/p&gt;</summary><content type="html">&lt;p&gt;So I've received my apparently mandated CIVX nickname, despite it
possibly being inaccurate in a week or two. I, along with &lt;a class="reference external" href="http://rebeccanatalie.com/"&gt;Pixel Ninja&lt;/a&gt;
and &lt;a class="reference external" href="http://foss.rit.edu/user/17"&gt;Python Princess&lt;/a&gt;, have been hacking away at our various tasks
together for over a week now, and despite the seemingly constant moving
from place to place, it's a pretty sweet gig.&lt;/p&gt;
&lt;p&gt;My work yesterday was some final polishing of the getall script, and my
first real push to the geowebdns repository. I'm also working on a
supplemental, informational guide to maintenance. Unfortunately, my
changes can't quite replace the old script yet, because the import
script (the one that actually starts to bring the files into the
database and do something with them) is hardcoded to the current files
and that script is a bit harder to hack than the download script. The
real work was on the documentation, trying to get people to understand
my reasoning behind the changes and allow for them to continue my work
without too much difficulty.&lt;/p&gt;
</content><category term="CIVX"></category><category term="democracymap"></category><category term="geowebdns"></category></entry></feed>